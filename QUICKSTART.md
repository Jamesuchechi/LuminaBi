# ğŸš€ Quick Start Guide - File Intelligence System

## Installation (2 minutes)

```bash
# 1. Install dependencies
pip install -r requirements.txt

# 2. Create migrations (if not already done)
python manage.py makemigrations

# 3. Apply migrations
python manage.py migrate

# 4. Verify setup
python manage.py check
# âœ… Should show: System check identified no issues (0 silenced)

# 5. Start server
python manage.py runserver
```

## Main URLs

| Feature | URL | Method |
|---------|-----|--------|
| ğŸ“¤ Upload File | `/datasets/upload/` | GET/POST |
| ğŸ“Š All Datasets | `/datasets/` | GET |
| ğŸ“‹ Dataset Detail | `/datasets/<id>/` | GET |
| ğŸ“ˆ Analysis View | `/datasets/<id>/analysis/` | GET |
| ğŸ“º File Viewer | `/datasets/<id>/viewer/` | GET |
| ğŸ—‘ï¸ Clean Data | `/datasets/<id>/remove-duplicates/` | POST |
| ğŸ“‰ Create Chart | `/datasets/<id>/visualizations/create/` | GET/POST |
| ğŸ“Š View Chart | `/datasets/visualization/<id>/` | GET |
| ğŸ“ˆ Dashboard | `/datasets/analytics/dashboard/` | GET |

## File Upload Workflow

```
1. Navigate to /datasets/upload/
2. Drag & drop file (or click to browse)
3. Select CSV, Excel, or JSON file
4. Enter dataset name and description
5. Click "Upload"
6. System automatically:
   - Detects file type
   - Analyzes structure
   - Detects quality issues
   - Calculates quality score
   - Creates analysis record
```

## Analysis Features

After upload, analysis includes:
- âœ… Row & column counts
- âœ… Empty cells (with coordinates: A4, B9, etc.)
- âœ… Duplicate detection
- âœ… Data type inference
- âœ… Missing values
- âœ… Outliers (IQR method)
- âœ… Column statistics (min, max, mean, median, std)
- âœ… Data quality score (0-100)

## Data Cleaning

Available operations:
1. **Remove Duplicates** - Detects and removes duplicate rows
2. **Fill Empty Cells** - Fill specific cells by address (A4, B9)
3. **Fill by Strategy** - Fill entire columns (mean, median, forward fill)
4. **Remove Whitespace** - Trim strings
5. **Normalize Columns** - Standardize column names
6. **Convert Types** - Change column data types
7. **Handle Missing** - Multiple strategies for missing values

Each operation creates a new version!

## Visualization Types

```
1. Line Chart      â†’ Trends over time
2. Bar Chart       â†’ Compare categories (grouped/stacked)
3. Scatter Plot    â†’ Find relationships
4. Histogram       â†’ Distribution of values
5. Pie Chart       â†’ Show proportions
6. Heatmap         â†’ Correlation matrix
7. Box Plot        â†’ Quartile analysis
8. Area Chart      â†’ Stacked areas over time
9. Distribution    â†’ Histogram + KDE curve
10. Pair Plot      â†’ (Placeholder for future)
```

## Creating a Visualization

```
1. Go to Dataset â†’ Click "Visualize"
2. Fill in form:
   - Title: "Sales by Region"
   - Chart Type: "Bar"
   - X Axis: "region"
   - Y Axis: Select "sales" and "profit"
3. Click "Preview" to see chart
4. Click "Save" to store visualization
5. View/Export in visualization detail page
```

## File Versions

Every cleaning operation creates a new version:
- Version 1: Original upload
- Version 2: First operation (e.g., duplicates removed)
- Version 3: Next operation (e.g., cells filled)
- etc.

**Tip**: You can switch versions in the file viewer!

## Analytics Dashboard

View comprehensive statistics:
- Total datasets, rows, visualizations
- Average data quality
- Operations breakdown
- Visualization type distribution
- File type distribution
- Data quality issues summary
- Recent activity feeds

## Supported File Formats

âœ… **CSV** - Comma-separated values
âœ… **Excel** - .xlsx and .xls files (with openpyxl)
âœ… **JSON** - JSON files
âœ… **Text** - Plain text files
â³ **PDF** - (placeholder, requires additional setup)
ğŸ–¼ï¸ **Images** - (placeholder, requires additional setup)

## Exporting Data

Export your cleaned data:
1. Go to File Viewer page
2. Select export format (CSV, JSON, Excel)
3. Download automatically starts

Or use REST API:
```bash
GET /datasets/<id>/export/?format=csv
GET /datasets/<id>/export/?format=json
GET /datasets/<id>/export/?format=excel
```

## REST API Examples

### Upload Dataset
```bash
curl -X POST http://localhost:8000/api/datasets/ \
  -H "Content-Type: multipart/form-data" \
  -F "file=@data.csv" \
  -F "name=My Dataset" \
  -F "description=Test data"
```

### Get Analysis
```bash
curl http://localhost:8000/api/datasets/123/analysis/
```

### Remove Duplicates
```bash
curl -X POST http://localhost:8000/api/datasets/123/deduplicate/ \
  -H "Content-Type: application/json"
```

### Get Statistics
```bash
curl http://localhost:8000/api/datasets/statistics/
```

## Data Quality Score Explained

Score: 0-100% based on:
- **Completeness** (40%): Ratio of non-null values
- **Uniqueness** (20%): Absence of duplicates
- **Consistency** (20%): Data type uniformity
- **Validity** (20%): Absence of outliers

Higher score = Better data quality

## Keyboard Shortcuts

- `Enter` in search box â†’ Filter datasets
- `Tab` to navigate forms
- `Ctrl+F` in file viewer â†’ Find in page

## Troubleshooting

**Q: Charts not showing?**
A: Install plotly - `pip install plotly`

**Q: File upload fails?**
A: Check file size (default max 5MB) and format

**Q: Empty cells not detected?**
A: Ensure file is properly formatted (no merged cells)

**Q: Analytics dashboard empty?**
A: Upload at least one dataset first

## System Check

Verify everything is working:
```bash
python manage.py check
# Output: System check identified no issues (0 silenced)
```

## Performance Tips

1. **Large Files**: Consider chunked processing
2. **Many Datasets**: Use pagination and search
3. **Visualizations**: Pre-filter data before charting
4. **Database**: Run migrations for optimal indexes

## Need Help?

1. Check Django logs: `tail -f logs/django.log`
2. Run system check: `python manage.py check`
3. Verify migrations: `python manage.py migrate --plan`
4. Test file parsing: Upload small test file first

## Development Commands

```bash
# Create admin user
python manage.py createsuperuser

# Access admin panel
http://localhost:8000/admin/

# Clear cache
python manage.py clear_cache

# Export data
python manage.py dumpdata datasets > backup.json

# Shell access
python manage.py shell
```

## What's New in This Release

âœ¨ **File Intelligence System v1.0**
- Complete file upload and analysis
- 7 data cleaning operations
- 10 interactive visualizations
- Full version history and rollback
- Comprehensive analytics dashboard
- Beautiful dark-themed UI
- REST API support
- Batch operations ready

## System Architecture

```
User Interface (9 templates)
        â†“
Django Views (15 views + API)
        â†“
Business Logic (4 services)
        â†“
Data Models (4 models)
        â†“
Database (SQLite with indexes)
```

## Next Steps

1. âœ… Install and verify setup
2. âœ… Upload your first CSV file
3. âœ… Explore analysis features
4. âœ… Create a visualization
5. âœ… View analytics dashboard
6. âœ… Try data cleaning operation
7. âœ… Check out version history

---

**Status**: Production Ready âœ…
**Last Updated**: 2024
**Version**: 1.0 Complete

For detailed documentation, see `FILE_INTELLIGENCE_SYSTEM.md` and `IMPLEMENTATION_COMPLETE.md`
